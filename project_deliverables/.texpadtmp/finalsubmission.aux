\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{encode2012integrated}
\citation{kundaje2015integrative}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{zhou2015predicting}
\citation{alipanahi2015predicting}
\citation{kelley2015basset}
\citation{quang2015danq}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Approach}{2}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment}{2}{section.4}}
\citation{quang2015danq}
\citation{zhou2015predicting}
\citation{encode2012integrated}
\citation{kundaje2015integrative}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The network architecture used to perform multitask prediction for a given input genomic sequence. Each character in the input sequence is mapped to a low-dimensional embedding, which is fed into a bi-directional recurrent neural network consisting of gated recurrent units. The outputs of the last GRU in the forwards and backwards RNNs are concatenated before being fed to one of $K$ prediction tasks. A final prediction of 1 or 0 is made for each task.}}{3}{figure.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Dataset}{3}{subsection.4.1}}
\citation{quang2015danq}
\citation{quang2015danq}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Character-Level Genome Prediction Results}{4}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Multitask Prediction Baseline and Evaluation Metric}{4}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Multitask Prediction Results}{5}{subsection.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The training and validation losses as functions of number of training epochs for the bidirectional RNN model. Training was done with 80,000 length-100 sequences across 919 binary labeling tasks.}}{5}{figure.2}}
\citation{zhou2015predicting}
\citation{zhou2015predicting}
\citation{koutnik2014clockwork}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces F1 scores for the logistic regression and RNN models for the 498 tasks with at least 800 positive training examples (out of 80000 total examples). The RNN epoch corresponding to the lowest validation error was epoch 33. Tasks where logistic regression achieved an F1 score of 0 were sorted instead by the F1 scores of the RNN with weights from epoch 33.}}{6}{figure.3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{6}{section.5}}
\bibstyle{plain}
\bibdata{cs224d}
\bibcite{alipanahi2015predicting}{1}
\bibcite{encode2012integrated}{2}
\bibcite{kelley2015basset}{3}
\bibcite{koutnik2014clockwork}{4}
\bibcite{kundaje2015integrative}{5}
\bibcite{quang2015danq}{6}
\bibcite{zhou2015predicting}{7}
