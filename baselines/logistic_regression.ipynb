{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Test different feature vectors for each sequence\n",
    "d = {'A':0,'G':1,'C':2,'T':3}\n",
    "\n",
    "# Construct k-mer dictionary\n",
    "kmer_to_ind = {}\n",
    "ind_to_kmer = {}\n",
    "k_ind = 0\n",
    "for k in range(1,6):\n",
    "    for kmer in [''.join(i) for i in itertools.product('ACGT', repeat = k)]:\n",
    "        kmer_to_ind[kmer] = k_ind\n",
    "        ind_to_kmer[k_ind] = kmer\n",
    "        k_ind += 1\n",
    "\n",
    "# Feature mapping 1: char to int\n",
    "def seq_to_int(s):\n",
    "    return map(lambda x: d[x], s)\n",
    "\n",
    "# Feature mapping 2: k-mer counting for k = 1, 2, 3, 4, 5\n",
    "def kmer_count(s):\n",
    "    v = np.zeros(len(kmer_d))\n",
    "    for k in range(1,6):\n",
    "        for kmer in [s[i:i+k] for i in range(len(s)-k+1)]:\n",
    "            v[kmer_to_ind[kmer]] += 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.21729278564e-05  s\n",
      "8.64791703224  s\n",
      "17.3691031933  s\n",
      "26.0988280773  s\n",
      "34.983520031  s\n",
      "43.8651061058  s\n",
      "52.6682171822  s\n",
      "61.4629561901  s\n",
      "4.41074371338e-05  s\n",
      "8.70831203461  s\n",
      "17.4135398865  s\n",
      "26.0699129105  s\n",
      "34.8625369072  s\n",
      "43.521682024  s\n",
      "52.1578481197  s\n",
      "60.8664290905  s\n",
      "69.54804492  s\n",
      "78.2283060551  s\n",
      "86.8684589863  s\n",
      "95.5575470924  s\n",
      "104.226825953  s\n",
      "112.869795084  s\n",
      "121.515153885  s\n",
      "130.167007923  s\n",
      "138.846755028  s\n",
      "147.533252954  s\n",
      "156.194768906  s\n",
      "165.07023406  s\n",
      "173.739531994  s\n",
      "182.390264988  s\n",
      "191.06633997  s\n",
      "199.732201099  s\n",
      "208.404450893  s\n",
      "217.128226042  s\n",
      "225.762731075  s\n",
      "234.395356894  s\n",
      "243.115035057  s\n",
      "251.792812109  s\n",
      "260.452189922  s\n",
      "269.121509075  s\n",
      "277.952056885  s\n",
      "286.624741077  s\n",
      "295.319360018  s\n",
      "303.982753038  s\n",
      "312.642975092  s\n",
      "321.49973011  s\n",
      "330.776637077  s\n",
      "339.473702908  s\n",
      "348.110438108  s\n",
      "356.801781893  s\n",
      "365.527770042  s\n",
      "374.184930086  s\n",
      "382.880213976  s\n",
      "391.550600052  s\n",
      "400.177983999  s\n",
      "408.946182966  s\n",
      "417.580282927  s\n",
      "426.281232119  s\n",
      "434.986295938  s\n",
      "443.657599926  s\n",
      "452.334708929  s\n",
      "461.001315117  s\n",
      "469.701004028  s\n",
      "478.346462965  s\n",
      "487.023914099  s\n",
      "495.728812933  s\n",
      "504.439197063  s\n",
      "513.144058943  s\n",
      "521.87944603  s\n",
      "530.594547987  s\n",
      "539.40683794  s\n",
      "548.168379068  s\n",
      "556.873100996  s\n",
      "565.515300989  s\n",
      "574.14969492  s\n",
      "582.755424976  s\n",
      "591.394882917  s\n",
      "600.008517981  s\n",
      "608.645410061  s\n",
      "617.25841403  s\n",
      "625.856910944  s\n",
      "634.456516981  s\n",
      "643.110892057  s\n",
      "651.799319029  s\n",
      "660.402209044  s\n",
      "669.014036894  s\n",
      "677.676944971  s\n",
      "686.266539097  s\n",
      "694.879983902  s\n",
      "703.54636097  s\n",
      "712.206623077  s\n",
      "720.816632032  s\n",
      "729.483712912  s\n",
      "738.191082001  s\n",
      "746.906595945  s\n",
      "755.568404913  s\n",
      "764.201877117  s\n",
      "772.850876093  s\n",
      "781.484836102  s\n",
      "790.16505599  s\n",
      "798.858115911  s\n",
      "807.630238056  s\n",
      "816.303297043  s\n",
      "824.95113802  s\n",
      "833.80725503  s\n",
      "842.545401096  s\n",
      "851.205667019  s\n",
      "859.794207096  s\n",
      "3.09944152832e-05  s\n",
      "8.57951998711  s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def load_features(feature_extractor,filename):\n",
    "    # Read in sequence\n",
    "    f = open(filename)\n",
    "    X = []\n",
    "    start_time = time.time()\n",
    "    for i,line in enumerate(f):\n",
    "        if i % 1000 == 0:\n",
    "            print time.time()-start_time, ' s'\n",
    "        X.append(feature_extractor(line.split()[0]))\n",
    "    return np.array(X)\n",
    "  \n",
    "fileprefix = '../jz-rnn-tensorflow/data/deepsea'\n",
    "feature_extractor = kmer_count\n",
    "# fileprefix = '../jz-rnn-tensorflow/data/positive/positive'\n",
    "X_test = load_features(feature_extractor,fileprefix + '.data.test.txt')\n",
    "X_train = load_features(feature_extractor,fileprefix + '.data.train.txt')\n",
    "# X_train = load_features(feature_extractor,'../deepsea_train/deepsea_feature915.data.train.txt')\n",
    "X_valid = load_features(feature_extractor,fileprefix + '.data.valid.txt')\n",
    "Y_test = np.loadtxt(fileprefix + '.labels.test.txt')\n",
    "Y_train = np.loadtxt(fileprefix + '.labels.train.txt')\n",
    "# Y_train = np.loadtxt('../deepsea_train/deepsea_feature915.labels.train.txt')\n",
    "Y_valid = np.loadtxt(fileprefix + '.labels.valid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump((X_test,X_train,X_valid,Y_test,Y_train,Y_valid),file('data.pickle','wb'))\n",
    "# X_test,X_train,X_valid,Y_test,Y_train,Y_valid = pickle.load(file('data.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e6)\n",
    "logreg.fit(X_train, Y_train)\n",
    "Yhat_train = logreg.predict(X_train)\n",
    "Yhat_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at error rates (F1)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print f1_score(Y_train,Yhat_train)\n",
    "print f1_score(Y_test,Yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
